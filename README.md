# **流式数据解决方案参考框架一**

**一 适用应用场景**

流式数据

低延时

...

**二 架构**

 

**（1）流程图**

![](D:\BIG-DATA\Flume_Kafka_Sparkstreaming\doc\架构.png)

 

**（2）处理流程**

Flume会实时监控写入日志的磁盘，只要有新的日志写入，Flume就会将日志以消息的形式传递给Kafka，然后Spark Streaming实时消费消息传入Hive

 

 

**（3）预期效果**

通过这套架构，收集到的日志可以及时被Flume发现传到Kafka，通过Kafka我们可以把日志用到各个地方，同一份日志可以存入Hdfs中，也可以离线进行分析，还可以实时计算，而且可以保证安全性，基本可以达到实时的要求。

 

**（4）效果计算分析**

每秒多少条，一天处理多少数据量，计算时效性

 

**三 部署流程**

硬件环境

至少3台服务器。

软件环境

CentOs 7.0

Jdk1.7/jdk1.8

...

 

1. 安装、配置flume

2. 安装、配置kafka

3. 安装、配置zookeeper

4. 安装、配置hadoop

5. 安装、配置hive

6. 安装、配置spark

7. 配置开发环境

   

 

 

**四 开发**

 

**五 测试**





