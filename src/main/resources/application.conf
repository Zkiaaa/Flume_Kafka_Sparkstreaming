// 项目配置文件
kxnf {
  //基础配置项 包括zookeeper kafka hdfs的基础配置
  runningModel{
    //testModel
    testModel = true
  }
  spark {
    driver.host = "10.0.0.139"
    executor.memory = "2g"
    serializer = "org.apache.spark.serializer.KryoSerializer"
    driver.memory = "512m"
    master = "local[4]"
    #master = "yarn-client"
    appName = "SparkBaseConf"
    clientModel = true //client model
    clusterModel = false //cluster model
  }
  basic {
    zkServers = "Master,Slave1,Slave2" //zookeeper地址 ---必须配置项
    zkport = "2181" //zookeeper端口 ---必须配置项
    kafkaBrokerList = "Master:9092,Slave1:9092,Slave2:9092" //kafka地址 ---必须配置项
    hdfsNameService = "nameservice1" //hadoop高可用设置的集群名称,没使用高可用则留空 ---必须配置项
    hdfsPath = "hdfs://Master:9000"
    zipFileScanPath="/test/unzip"
    backupFilePath = "/test/backup"
    rejectPath="/test/reject"
    scanLimits = "12" //限制文件数 一般计算公式 节点个数 * core数 42 = 3 * 14
    #zipFileScanPath="/infosouth/zipFiles"
    #backupFilePath = "/infosouth/backup"
    moveFlag = "true"
    csvImportFlag = "false"
    csvFileMoveFlag = "false"
    dstCSVParentPath = "/infosouth/exports"
  }
  //后面可以考虑引入
  redis {
    //此处为redis的主从模式集群
    hosts = "192.168.46.14:26379,192.168.46.9:26379,192.168.46.12:26379" //redis地址 ---必须配置项
    masterName = "mymaster"
    maxTotal = 5 //最大连接数 可增大
    maxIdle = 1 //最大的空闲数
    maxWaitMillis = 10000
    dbIndex = 8 //redis 数据库索引 一般有16个库可用
  }

  //sql server信息 --必须配置项
  sqlServer {
    ip = "10.0.0.80"
    port = 3306
    user = "root"
    password = "root"
  }

  mysql {
    ip = "10.0.0.80"
    port = 3306
    user = "root"
    password = "root"
    database = "amas_xiamen"
  }
  //csv文件处理配置项

  decodeInfo{
    masterIp = "10.0.0.120"
    sendDecodeMsgPort = "8888"
    sendDecodeUrl = ""
  }
}